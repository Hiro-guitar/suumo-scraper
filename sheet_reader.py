import gspread
from google.oauth2.service_account import Credentials
from suumo_scrape import extract_conditions_from_url
from suumo_search_url import build_suumo_search_url
from suumo_checker import find_matching_property, check_company_name
import datetime
import pytz

# === è¨­å®š ===
SPREADSHEET_ID_SOURCE = '1oZKxfoZbFWzTfZvSU_ZVHtnWLDmJDYNd6MSfNqlB074'
SOURCE_RANGE = 'A:J'

SPREADSHEET_ID = '195OS2gb97TUJS8srYlqLT5QXuXU0zUZxmbeuWtsGQRY'
SHEET_NAME = 'Sheet1'

SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
creds = Credentials.from_service_account_file('credentials.json', scopes=SCOPES)
client = gspread.authorize(creds)

# === å…ƒã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° ===
def get_source_data():
    sheet = client.open_by_key(SPREADSHEET_ID_SOURCE).sheet1
    result = sheet.get(SOURCE_RANGE)
    return [(row[0], row[1], row[9]) for row in result if len(row) >= 10 and row[0] and row[9].startswith('http')]

# === å¯¾è±¡ã‚·ãƒ¼ãƒˆèª­ã¿è¾¼ã¿ ===
target_sheet = client.open_by_key(SPREADSHEET_ID).worksheet(SHEET_NAME)

# === ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è»¢è¨˜ï¼ˆå±¥æ­´ä¿æŒãƒ¢ãƒ¼ãƒ‰ï¼‰ ===
existing_values = target_sheet.get_all_values()
existing_map = {}  # {(ç‰©ä»¶å, éƒ¨å±‹ç•ªå·): è¡Œç•ªå·}
rows_to_keep = set()

for idx, row in enumerate(existing_values[1:], start=2):  # ãƒ˜ãƒƒãƒ€ãƒ¼é™¤å¤–
    if len(row) >= 2:
        key = (row[0], row[1])
        existing_map[key] = idx

property_data = get_source_data()

for (title, room_no, url) in property_data:
    key = (title, room_no)
    if key in existing_map:
        row_idx = existing_map[key]
        target_sheet.update_cell(row_idx, 3, url)  # Cåˆ— = URL
        rows_to_keep.add(row_idx)
    else:
        target_sheet.append_row([title, room_no, url])
        new_row = len(target_sheet.get_all_values())
        rows_to_keep.add(new_row)

# === å¤ã„è¡Œã‚’å‰Šé™¤ï¼ˆå…ƒã‚·ãƒ¼ãƒˆã«å­˜åœ¨ã—ãªã„ç‰©ä»¶ï¼‰ ===
rows_all = set(existing_map.values())
rows_to_delete = sorted(rows_all - rows_to_keep, reverse=True)

for row_idx in rows_to_delete:
    target_sheet.delete_rows(row_idx)

# === çµæœåˆ—ã®è¿½åŠ æº–å‚™ ===
all_values = target_sheet.get_all_values()
max_col = max((len(row) for row in all_values if any(cell.strip() for cell in row)), default=0)
col_index = max_col + 1

if target_sheet.col_count < col_index:
    target_sheet.add_cols(col_index - target_sheet.col_count)

# === æ—¥æ™‚ãƒ©ãƒ™ãƒ«è¨˜å…¥ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ ===
tokyo = pytz.timezone('Asia/Tokyo')
now = datetime.datetime.now(tokyo)
timestamp = now.strftime("%m-%d %H:%M")
target_sheet.update_cell(1, col_index, timestamp)

# === ãƒã‚§ãƒƒã‚¯å‡¦ç†æœ¬ä½“ ===
for i, (_, _, url) in enumerate(property_data, start=2):
    if not url.strip().startswith("http"):
        continue

    print(f"ğŸ”— å‡¦ç†ä¸­: {url}")
    result = extract_conditions_from_url(url)

    if result:
        print(f"ğŸ  ç‰©ä»¶å: {result.get('title', 'N/A')}")

        search_url = build_suumo_search_url(
            station_info=result['stations'],
            price=result['price'],
            area_max=result['area'],
            age_max=result['age'],
            floor_plan=result['floor_plan']
        )

        if search_url:
            print(f"ğŸ” æ¤œç´¢URL: {search_url}")
            target_sheet.update_cell(i, 4, search_url)  # Dåˆ—

            detail_url = find_matching_property(search_url, result)

            if detail_url:
                if check_company_name(detail_url):
                    print("â­•ï¸ ãˆã»ã†ã¾ããŒæ²è¼‰ä¸­ï¼")
                    target_sheet.update_cell(i, col_index, "â­•ï¸")
                else:
                    print("âŒ ä»–ç¤¾æ²è¼‰")
                    target_sheet.update_cell(i, col_index, "âŒ")
            else:
                print("ğŸ” ä¸€è‡´ç‰©ä»¶ãªã—")
                target_sheet.update_cell(i, col_index, "")
        else:
            print("âš ï¸ æ¤œç´¢URLä½œæˆå¤±æ•—")
            target_sheet.update_cell(i, col_index, "URLå¤±æ•—")
    else:
        print("âš ï¸ æ¡ä»¶æŠ½å‡ºå¤±æ•—")
        target_sheet.update_cell(i, col_index, "æŠ½å‡ºå¤±æ•—")
